package main

import (
	"context"
	"flag"
	"fmt"
	"io/ioutil"
	"os"
	"os/signal"
	"sync"
	"syscall"
	"time"

	"github.com/ghodss/yaml"
	"github.com/go-logr/logr"
	uzap "go.uber.org/zap"
	corev1 "k8s.io/api/core/v1"
	k8serrors "k8s.io/apimachinery/pkg/api/errors"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
	"k8s.io/apimachinery/pkg/runtime"
	"k8s.io/apimachinery/pkg/runtime/schema"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/client-go/dynamic"
	"k8s.io/client-go/tools/clientcmd"
	"sigs.k8s.io/controller-runtime/pkg/log"
	"sigs.k8s.io/controller-runtime/pkg/log/zap"

	"net/http"
	_ "net/http/pprof"
)

var (
	s = runtime.NewScheme()
)

func init() {
	log.SetLogger(zap.New(zap.RawZapOpts(uzap.AddCallerSkip(1)), zap.UseDevMode(true)))
	// SchemeGroupVersion is group version used to register these objects

}

func main() {
	kubeconfig := flag.String("kubeconfig", os.Getenv("KUBECONFIG"), "absolute path to the kubeconfig file")
	concurentNum := flag.Int("n", 10, "number of concurrent clients")
	duration := flag.Int("d", 10, "duration for running this test, in second")
	path := "./manifestwork-template.yaml"

	flag.Parse()

	logger := log.Log.WithName("etcd-replayer")

	wg := &sync.WaitGroup{}

	stop := make(chan struct{})

	w := &unstructured.Unstructured{}

	dat, err := ioutil.ReadFile(path)
	if err != nil {
		logger.Error(err, "failed to read template")
		os.Exit(1)
	}

	if err := yaml.Unmarshal(dat, w); err != nil {
		logger.Error(err, "failed to parse template")
		os.Exit(1)
	}

	logger.Info(fmt.Sprintf("testing at %v(duration), %v(concurrent update client numbers)", *duration, *concurentNum))

	go func() {
		logger.Error(http.ListenAndServe("localhost:6060", nil), "pperf server")
	}()

	runners := []*Runner{}

	now := time.Now()
	for idx := 0; idx < *concurentNum; idx++ {
		t := NewRunner(
			WithNameSuffix(idx),
			WithClient(*kubeconfig, logger),
			WithTemplate(w),
			WithStop(stop),
			WithWaitGroup(wg),
			WithLogger(logger))

		t.initial()
		if err := t.create(); err == nil {
			runners = append(runners, t)
		}

	}

	logger.Info(fmt.Sprintf("created %v templates in %v seconds", len(runners), time.Now().Sub(now).Seconds()))

	for _, r := range runners {
		wg.Add(1)
		go r.update()
	}

	c := make(chan os.Signal)
	signal.Notify(c, os.Interrupt, syscall.SIGTERM)

	dur := time.Duration(*duration) * time.Second
	timeout := time.After(dur)

	defer func() {
		for _, r := range runners {
			r.delete()
		}
	}()

	select {
	case <-c:
		close(stop)
		logger.Info("system interrupt")
	case <-timeout:
		close(stop)
		logger.Info(fmt.Sprintf("stop after %v", time.Now().Sub(now).Seconds()))
	}

	wg.Wait()
}

type Option func(*Runner)

func NewRunner(ops ...Option) *Runner {
	r := &Runner{}

	for _, ops := range ops {
		ops(r)
	}

	return r
}

type Runner struct {
	name     string
	Client   dynamic.Interface
	template *unstructured.Unstructured
	stop     chan struct{}
	logger   logr.Logger
	wg       *sync.WaitGroup
}

func WithClient(kubeconfig string, logger logr.Logger) Option {
	cfg, err := clientcmd.BuildConfigFromFlags("", kubeconfig)
	if err != nil {
		logger.Error(err, "failed to load rest.Config")
		os.Exit(1)
	}

	cfg.QPS = 200.0
	cfg.Burst = 400

	dc := dynamic.NewForConfigOrDie(cfg)

	return func(r *Runner) {
		r.Client = dc
	}
}

func WithTemplate(w *unstructured.Unstructured) Option {
	return func(r *Runner) {
		r.template = w.DeepCopy()
	}
}

func WithNameSuffix(s int) Option {
	return func(r *Runner) {
		r.name = fmt.Sprintf("%v", s)
	}
}

func WithLogger(logger logr.Logger) Option {
	return func(r *Runner) {
		r.logger = logger
	}
}

func WithWaitGroup(wg *sync.WaitGroup) Option {
	return func(r *Runner) {
		r.wg = wg
	}
}

func WithStop(stop chan struct{}) Option {
	return func(r *Runner) {
		r.stop = stop
	}
}

func (r *Runner) initial() {
	payload := r.template.DeepCopy()

	ns := &corev1.Namespace{
		ObjectMeta: metav1.ObjectMeta{
			Name: fmt.Sprintf("%s-%v", payload.GetName(), r.name),
		},
	}

	key := types.NamespacedName{
		Name:      fmt.Sprintf("%s-%v", payload.GetName(), r.name),
		Namespace: ns.Name,
	}

	payload.SetNamespace(key.Namespace)
	payload.SetName(key.Name)

	r.template = payload.DeepCopy()
}

var (
	nsGVR       = schema.GroupVersionResource{Version: "v1", Resource: "namespaces"}
	manifestGVR = schema.GroupVersionResource{
		Group:    "work.open-cluster-management.io",
		Version:  "v1",
		Resource: "manifestworks",
	}
)

func (r *Runner) create() error {
	ctx := context.TODO()

	ns := &unstructured.Unstructured{
		Object: map[string]interface{}{
			"apiVersion": "v1",
			"kind":       "Namespace",
			"metadata": map[string]interface{}{
				"name": r.template.GetNamespace(),
			},
		},
	}

	if _, err := r.Client.Resource(nsGVR).Create(ctx, ns, metav1.CreateOptions{}); err != nil {
		if !k8serrors.IsAlreadyExists(err) {
			r.logger.Error(err, "failed to create namespace")
			return err
		}

	}

	t := r.template.DeepCopy()

	if v, err := r.Client.Resource(manifestGVR).Namespace(t.GetNamespace()).Create(ctx, t, metav1.CreateOptions{}); err != nil {
		if !k8serrors.IsAlreadyExists(err) {
			r.logger.Error(err, fmt.Sprintf("failed to create manifestwork: %s\n%v", r.getKey(), v))
			return err
		}
	}

	//r.logger.Info(fmt.Sprintf("created %s", key))

	return nil
}

func (r *Runner) getKey() types.NamespacedName {
	return types.NamespacedName{
		Name:      r.template.GetName(),
		Namespace: r.template.GetNamespace(),
	}

}

func (r *Runner) delete() {
	ctx := context.TODO()
	if err := r.Client.Resource(manifestGVR).Namespace(r.getKey().Namespace).Delete(ctx, r.getKey().Name, metav1.DeleteOptions{}); err != nil {
		r.logger.Error(err, fmt.Sprintf("failed to delete manifestwork: %s", r.getKey()))
	}

	ns := &corev1.Namespace{
		ObjectMeta: metav1.ObjectMeta{
			Name: r.template.GetNamespace(),
		},
	}
	if err := r.Client.Resource(nsGVR).Delete(ctx, ns.GetName(), metav1.DeleteOptions{}); err != nil {
		r.logger.Error(err, "failed to delete namespace")
	}
}

func (r *Runner) update() {
	r.logger.Info(fmt.Sprintf("start to run %s", r.name))

	ctx := context.TODO()

	key := r.getKey()

	go func() {
		suffix := 1
		ticker := time.NewTicker(10 * time.Millisecond)
		defer ticker.Stop()

		defer func() {

			r.wg.Done()
		}()

		for {
			select {
			case <-r.stop:
				return

			case <-ticker.C:
				originalIns, err := r.Client.Resource(manifestGVR).Namespace(key.Namespace).Get(ctx, key.Name, metav1.GetOptions{})

				if err != nil {
					r.logger.Error(err, "failed to Get")
					continue
				}

				t := originalIns.DeepCopy()

				labels := t.GetLabels()

				if labels == nil {
					labels = map[string]string{}
				}

				// Update the ReplicaSet
				labels["hello"] = fmt.Sprintf("world-%v", suffix)
				suffix += 1

				t.SetLabels(labels)

				d, err := t.MarshalJSON()
				if err != nil {
					r.logger.Error(err, "failed to MarshalJSON")
				}

				if _, err := r.Client.Resource(manifestGVR).Namespace(key.Namespace).Patch(ctx, key.Name, types.MergePatchType, d, metav1.PatchOptions{}); err != nil {
					r.logger.Error(err, "failed to update")
				}
			}
		}
	}()
}
